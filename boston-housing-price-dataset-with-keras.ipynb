{"cells":[{"metadata":{"_uuid":"452ca30a3ce0a2dc1b59b3f84f0c7f02ccbd7319"},"cell_type":"markdown","source":"**This is an example from Deep Learning With Python book.**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76c00e3b6e596e30ba6728c95ef323389dca5537"},"cell_type":"markdown","source":"## Loading the dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from keras.datasets import boston_housing\n\n(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46abef54b50bee09d016f30786d79dda2171ad3c"},"cell_type":"code","source":"# take a look at the data\n\nprint(f'Training data : {train_data.shape}')\nprint(f'Test data : {test_data.shape}')\nprint(f'Training sample : {train_data[0]}')\nprint(f'Training target sample : {train_targets[0]}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06d8318b1e09e6dffb161fab36b324a309b25b6a"},"cell_type":"markdown","source":"## Preparing the data\n\nWe are going to do a feature normalization . Feature normalizaion is when you subtract the mean of the feature from each feature and divide each result by the standard deviation.\n"},{"metadata":{"trusted":true,"_uuid":"fb47c40e26f4a56384584910c748eea00cfd7159"},"cell_type":"code","source":"mean = train_data.mean(axis=0)\ntrain_data -= mean\nstd = train_data.std(axis=0)\ntrain_data /= std\n\ntest_data -= mean\ntest_data /= std\n\n# Note that the quantities used for normalizing the test data are computed using the\n# training data. You should never use in your workflow any quantity computed on the\n# test data, even for something as simple as data normalization.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26834f67baa2de9d4b516b1f8eaafc5737276fce"},"cell_type":"markdown","source":"## Building the network"},{"metadata":{"trusted":true,"_uuid":"4cbaa8646f81bab4261e9c25474cef65b2fc8474"},"cell_type":"code","source":"from keras import models\nfrom keras import layers\n\ndef build_model():\n    model = models.Sequential()\n    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(1))\n\n    model.compile(optimizer='rmsprop',\n              loss='mse',\n              metrics=['mae'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bddd23bd4517bcbedb3e264249a39cf851a9acfd"},"cell_type":"markdown","source":"## K-fold validation"},{"metadata":{"trusted":true,"_uuid":"e9ccbfd3c006f5a51da9e83809f601cf651c02dc"},"cell_type":"code","source":"k = 4\nnum_val_samples = len(train_data) // k\nnum_epochs = 100\nall_scores = []\n\nfor i in range(k):\n    print(f'Processing fold # {i}')\n    val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]\n    val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]\n    \n    partial_train_data = np.concatenate(\n                            [train_data[:i * num_val_samples],\n                            train_data[(i+1) * num_val_samples:]],\n                            axis=0)\n    partial_train_targets = np.concatenate(\n                            [train_targets[:i * num_val_samples],\n                            train_targets[(i+1)*num_val_samples:]],\n                            axis=0)\n    model = build_model()\n    model.fit(partial_train_data,\n              partial_train_targets,\n              epochs=num_epochs,\n              batch_size=1,\n              verbose=0)\n    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n    all_scores.append(val_mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a9f7c987f6f29ea22a03c3df0688d9e38ea8f05"},"cell_type":"code","source":"print(f'all_scores : {all_scores}')\nprint(f'mean all scores : {np.mean(all_scores)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"328b6245ae5d964df08f14de6236bc68147c5611"},"cell_type":"code","source":"model = build_model()\nmodel.fit(train_data, train_targets, epochs=80, batch_size=16, verbose=0)\ntest_mse_score, test_mae_score = model.evaluate(test_data, test_targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"174d90326f6ed72d9127f6cf8d0619a4820d56e5"},"cell_type":"code","source":"test_mae_score","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}